The market data consumer component in a market participant's trading system is the direct complement of the market data publisher component in the electronic trading exchange. 
It is responsible for subscribing to and consuming the multicast network traffic that the exchange publishes, decoding and normalizing the market data it reads from the exchange protocol to an internal format, and implementing packet drop-related synchronization mechanisms.
Here are some of the designs in detail: 

	1) Subscribing to and consuming UDP multicast traffic: The first task is to subscibe to the multicast stream that the exchange is publishing market data on. Typically, in the intrest of load balancing, the exchange groups different trading instruments on different multicast stream address. 

	2) Decoding and normalizing from exchange protocol: Next, the market data consumer needs to do is convert from the exchange market data protocol into an internal format that the rest of the components in the participant's system use. The fastest protocols are the ones where minimal decoding is required, such as EOBI and SBE, which are just binary-packed structures. 

	3) Synchronizing on startup and packet drops: To make sure that market participants see market data packets in the correct order, as well as detect packet drops when they occur, typically, there are packet-level and instrument-level sequence numbers that the participants should check. Another thing that needs to be designed, both on the exchnage market data publisher and the participants market data consumers, is a mechanism to revocer from such packet drops. 

	4)*Incremental market data streams: The incremental market data stream assumes that the market participant already has the correct view of the limit order book maintained by the matching engine, and this stream only publishes incremental updates to the previous stat of the order book. If the client drops a packet from this stream, then the stat of the order book that they maintain might be incronsistent with what the matching engine has. The mechanism to handle this failure is to clear or reset the order book that the participant maintains Then it needs to subscibe to the snapshot stream, which contains data for the full state of the entire order book to synchronize to the correct state of the book once again. The protocol here is to clear the book, start queuing up incremental updates received from the incremental stream and wait to build the full stat of the order book, and then apply the invcremental updates to that full order book to finsih the synchronization.

	5) *Snapshot market data streams: The market data stream contains data that can be used to build the full order book from a completely empty state. Since this stream contains infromation about all the orders in the order book for every single trading instrument, it can become quite bandwidth-heavy. Since packet drops are an exceedingly rare occurrence and participants do not mind waiting a few seconds when thye first start up to grab the correct stat of the order book, the throttling does not usually have a large negative impact. 
